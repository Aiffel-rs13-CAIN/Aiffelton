import autogen
import testbed_utils
import re

testbed_utils.init()
##############################

# Read the prompt
PROMPT = ""
with open("prompt.txt", "rt") as fh:
    PROMPT = fh.read()


# answer.txtë¡œë¶€í„° ì •ë‹µ ì½ê¸°
correct_answer = ""
explanation = ""

# Read the answer
ANSWER = "__ANSWER__"

with open("answer.txt", "r", encoding="utf-8") as f:
    for line in f:
        if line.startswith("__ANSWER__"):
            correct_answer = line.split("=", 1)[1].strip()
        elif line.startswith("__EXPLAIN__"):
            explanation = line.split("=", 1)[1].strip()


config_list1 = autogen.config_list_from_json("OAI_CONFIG_LIST",
                                            filter_dict={"model": ["deepseek/deepseek-chat-v3.1:free"]})

config_list2 = autogen.config_list_from_json("OAI_CONFIG_LIST",
                                            filter_dict={"model": ["gemini-1.5-flash"]})

gp_system_message = """
ë‹¹ì‹ ì€ ë¯¸êµ­ ì˜ì‚¬ë©´í—ˆì‹œí—˜(USMLE) Step 1 ë° Step 2 ìˆ˜ì¤€ì˜ ì§€ì‹ì„ ê°–ì¶˜ ìœ ëŠ¥í•œ ì¼ë°˜ì˜ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì—­í• ì€ í™˜ì ì •ë³´, ì„ìƒ ìƒí™©, ì¹˜ë£Œ ì˜µì…˜ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ì§„ë‹¨, ì²˜ì¹˜ ë˜ëŠ” ìœ¤ë¦¬ì  ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì…ë‹ˆë‹¤.

- í•­ìƒ ì˜í•™ì  ì‚¬ì‹¤ê³¼ í‘œì¤€ ì§„ë£Œì§€ì¹¨ì— ê¸°ë°˜í•˜ì—¬ íŒë‹¨í•˜ì„¸ìš”.
- ì„ íƒì§€ ì¤‘ì—ì„œ ê°€ì¥ ì•ˆì „í•˜ê³  í™˜ìì˜ ì´ìµì— ë¶€í•©í•˜ëŠ” ë‹µì„ ê³ ë¥´ì„¸ìš”.
- ë¶ˆí™•ì‹¤í•œ ê²½ìš°ì—ëŠ” ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²ƒì„ íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìœ¼ì„¸ìš”.
- ì§ˆë¬¸ì— ì£¼ì–´ì§„ ì •ë³´ ì™¸ì˜ ì¶”ì¸¡ì€ í”¼í•˜ì„¸ìš”.
- ì„ íƒì§€ëŠ” A, B, C, D, E ë“±ìœ¼ë¡œ ì£¼ì–´ì§€ë©°, ê·¸ ì¤‘ ê°€ì¥ ì ì ˆí•œ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ: "ì •ë‹µì€ Cì…ë‹ˆë‹¤. í•´ë‹¹ ì„ íƒì§€ëŠ” â€¦ ì´ìœ ë¡œ ê°€ì¥ ì ì ˆí•©ë‹ˆë‹¤."
"""

# OpenRouter ì „ìš© LLM ì„¤ì •
llm_config1 = {
    "config_list": config_list1,
    "temperature": 0.2,
    "timeout": 60,
    "cache_seed": None, 
    "max_tokens": 1000   
}

llm_config2 = {
    "config_list": config_list2,
    "temperature": 0.2,  
    "timeout": 60,
    "cache_seed": None, 
    "max_tokens": 1000   
}


doctor1 = autogen.AssistantAgent(
    "ì˜ë£Œì§„_ë°•ì‚¬", 
    system_message=gp_system_message, 
    is_termination_msg=lambda x: x.get("content", "").find("TERMINATE") >= 0,
    llm_config=llm_config1)

doctor2 = autogen.AssistantAgent(
    "ì˜ë£Œì§„_êµìˆ˜", 
    system_message=gp_system_message,
    is_termination_msg=lambda x: x.get("content", "").find("TERMINATE") >= 0,
    llm_config=llm_config2)

# # ì •ë‹µ í™•ì¸ í•¨ìˆ˜
# def check_answer(agent, messages, sender, config, **kwargs):
#     print("âœ… check_answer í•¨ìˆ˜ í˜¸ì¶œë¨")
#     print(f"Sender: {sender.name}")

#     if not messages:
#         return True, {
#             "role": "user",
#             "content": "âš ï¸ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
#         }

#     latest_msg = messages[-1]
#     print(f"[ì±„ì  ì¤‘] assistantì˜ ì‘ë‹µ: {latest_msg['content']}")
#     if correct_answer in latest_msg["content"]:
#         return True, {
#             "role": "user",
#             "content": "âœ… ì •ë‹µì…ë‹ˆë‹¤!"
#         }
#     else:
#         return True, {
#             "role": "user",
#             "content": f"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct_answer}ì…ë‹ˆë‹¤."
#         }
    
    # ì •ë‹µ í™•ì¸ í•¨ìˆ˜
def check_answer(agent, messages, sender, config, **kwargs):
    print(f"âœ… check_answer í•¨ìˆ˜ í˜¸ì¶œë¨ : {correct_answer}")
    print(f"Sender: {sender.name}")


    if not messages:
        return True, {
            "role": "user",
            "content": "âš ï¸ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    latest_msg = messages[-1]
    content = latest_msg.get("content", "")
    print(f"[ì±„ì  ì¤‘] assistantì˜ ì‘ë‹µ: {content}")

    # "ì •ë‹µì€ Xì…ë‹ˆë‹¤"ì—ì„œ X ì¶”ì¶œ
    match = re.search(r"ì •ë‹µì€\s*([A-E])\s*", content)
   
    if match:
        extracted_answer = match.group(1)
        print(f"[ì±„ì  ì¤‘] ì¶”ì¶œëœ ë‹µë³€: {extracted_answer}")

        # Autogenì˜ generate_reply()ëŠ” (final, reply) í˜•íƒœë¡œ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì— ë¨¼ì € finalì„ Trueë¡œ ì„¤ì •í•˜ê³  replyë¥¼ ë°˜í™˜
        if extracted_answer == correct_answer:
            return True, {
                "role": "user",
                "content": "âœ… ì •ë‹µì…ë‹ˆë‹¤!"
            }
        else:
            return True, {
                "role": "user",
                "content": f"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct_answer}ì…ë‹ˆë‹¤."
            }
    else:
        # í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
        return True, {
            "role": "user",
            "content": "âš ï¸ ì •ë‹µ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('ì •ë‹µì€ Xì…ë‹ˆë‹¤' í˜•ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.)"
        }


# í† ë¡  ì¤‘ì¬ì ì„¤ì •
moderator = autogen.UserProxyAgent(
    "í† ë¡ _ì¤‘ì¬ì",
    # code_execution_config={"use_docker": False},
    code_execution_config=False,
    human_input_mode="NEVER",
    default_auto_reply="TERMINATE",
    #is_termination_msg=lambda x: "ì •ë‹µì…ë‹ˆë‹¤" in x.get("content", "") or "TERMINATE" in x.get("content", ""),
    #max_consecutive_auto_reply=1
)

print(f"ğŸ¥ ì˜ë£Œì§„ í† ë¡  ì‹œì‘")
print(f"ğŸ“ ë¬¸ì œ ì¶œì œ ì¤‘...")

# ê·¸ë£¹ ì±„íŒ… ì„¤ì •
groupchat = autogen.GroupChat(
    agents=[moderator, doctor1, doctor2], 
    messages=[], 
    max_round=4, 
    speaker_selection_method="round_robin",
    allow_repeat_speaker=False
)

# ê·¸ë£¹ ì±„íŒ… ë§¤ë‹ˆì €
manager = autogen.GroupChatManager(
    groupchat=groupchat, 
    llm_config=llm_config1
)

# register_replyë¥¼ initiate_chat í˜¸ì¶œ ì „ì— ë“±ë¡
moderator.register_reply(
    trigger=manager,
    reply_func=check_answer
)

# í† ë¡  ì‹œì‘
print("ğŸ—£ï¸ ì˜ë£Œì§„ í† ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
discussion_prompt = f"""
ë‹¤ìŒ ì˜ë£Œ ì‚¬ë¡€ì— ëŒ€í•´ í† ë¡ í•´ì£¼ì„¸ìš”:

{PROMPT}

ë‘ ì˜ë£Œì§„ì€ ê°ìì˜ ì˜ê²¬ì„ ì œì‹œí•˜ê³ , ì„œë¡œì˜ ê´€ì ì„ ê³ ë ¤í•˜ì—¬ í† ë¡ í•œ í›„ ìµœì¢… í•©ì˜ì•ˆì„ ë„ì¶œí•´ì£¼ì„¸ìš”.
í† ë¡ ì´ ëë‚˜ë©´ "ìµœì¢…ë‹µë³€: [A/B/C/D/E]" í˜•ì‹ìœ¼ë¡œ ê²°ë¡ ì„ ë‚´ë ¤ì£¼ì„¸ìš”.
"""

# í† ë¡  ì‹¤í–‰ (í•œ ë²ˆë§Œ)
moderator.initiate_chat(
    manager,
    message=PROMPT
    #max_turns=10
)

print(f"\nğŸ’¬ í† ë¡  ì™„ë£Œ!")


# # í† ë¡  ê²°ê³¼ ë¶„ì„
# print("\nğŸ“Š í† ë¡  ê²°ê³¼ ë¶„ì„ ì¤‘...")
# conversation_history = chat_result.chat_history if hasattr(chat_result, 'chat_history') else []

# # ëŒ€í™” ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš° groupchatì—ì„œ ê°€ì ¸ì˜¤ê¸°
# if not conversation_history:
#     conversation_history = groupchat.messages

# result = check_answer(conversation_history)
# print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼: {result}")

# print(f"\nğŸ’¬ í† ë¡  ìš”ì•½:")
# for i, msg in enumerate(conversation_history[-3:]):  # ë§ˆì§€ë§‰ 3ê°œ ë©”ì‹œì§€ë§Œ í‘œì‹œ
#     speaker = msg.get("name", "Unknown")
#     content = msg.get("content", "")[:200] + "..." if len(msg.get("content", "")) > 200 else msg.get("content", "")
#     print(f"ğŸ¯ {speaker}: {content}")

##############################
testbed_utils.finalize(agents=[moderator, doctor1, doctor2, manager])