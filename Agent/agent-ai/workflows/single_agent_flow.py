from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage
from typing import TypedDict, Annotated, Sequence
import operator
from dotenv import load_dotenv

# ì›Œí¬í”Œë¡œìš° íŒ©í† ë¦¬ import
from workflows.workflow_factory import WorkflowFactory

load_dotenv()

#ê·¸ë˜í”„ ìƒíƒœ(ë©”ëª¨ë¦¬) ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    context: str = ""
    memory: dict = {}
    tool_results: list = []
    should_exit: bool = False
    user_id: str = "default_user"
    last_response: str = ""

def create_single_agent_workflow(agent_core):
    factory = WorkflowFactory(agent_core)

    workflow = StateGraph(AgentState)

    workflow.add_node("user_input", factory.user_input_node_func)
    workflow.add_node("memory", factory.memory_node_func)
    workflow.add_node("rag", factory.rag_node_func)
    workflow.add_node("llm", factory.llm_node_func)
    workflow.add_node("tools", factory.tool_node_func)
    workflow.add_node("mcp_tools", factory.mcp_tool_node_func) # MCP ë„êµ¬ ë…¸ë“œ ì¶”ê°€
    workflow.add_node("output", factory.output_node_func)

    workflow.set_entry_point("user_input")

    # ì‚¬ìš©ì ì…ë ¥ í›„ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸
    workflow.add_conditional_edges(
        "user_input",
        factory.should_exit,
        {
            "exit": END,
            "continue": "memory"
        }
    )

    # ë©”ëª¨ë¦¬ -> RAG -> LLM ìˆœì„œë¡œ ì§„í–‰ (MCP ë„êµ¬ëŠ” LLM ì´í›„ë¡œ ì´ë™)
    workflow.add_edge("memory", "rag")

    # âœ… RAGì™€ LLM ì‚¬ì´ì— MCP ë„êµ¬ ê²°ì • ë¡œì§ ì¶”ê°€
    def decide_before_llm(state):
        messages = state.get("messages", [])
        if not messages:
            return "output"

        last_user_msg = messages[0]  # ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ ì‚¬ìš©ì ë©”ì‹œì§€ë¼ê³  ê°€ì •
        if hasattr(last_user_msg, 'content'):
            content = str(last_user_msg.content).lower()

            time_keywords = [
                'ì‹œê°„', 'í˜„ì¬ì‹œê°„', 'ì§€ê¸ˆì‹œê°„', 'ëª‡ì‹œ', 'ì‹œê°',
                'time', 'current time', 'what time',
                'ë‚ ì§œ', 'ì˜¤ëŠ˜', 'ì§€ê¸ˆ', 'date', 'today', 'now',
                'ì–¸ì œ', 'when'
            ]

            for keyword in time_keywords:
                if keyword in content:
                    print(f"ğŸ•’ ì‹œê°„ ê´€ë ¨ í‚¤ì›Œë“œ '{keyword}' ê°ì§€, MCP ë„êµ¬ ì‹¤í–‰")
                    return "mcp_tools"

        # ì‹œê°„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ LLMìœ¼ë¡œ ì§„í–‰
        return "llm"

    workflow.add_conditional_edges(
        "rag",  # RAG ë…¸ë“œ ë‹¤ìŒì— ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
        decide_before_llm,
        {
            "mcp_tools": "mcp_tools",
            "llm": "llm"
        }
    )

    # LLM ë…¸ë“œ í›„ì—ëŠ” íˆ´ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ë°”ë¡œ ì¶œë ¥ìœ¼ë¡œ ì´ë™
    def decide_after_llm_simplified(state):
        """LLM í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì • - ì‹œê°„ ê´€ë ¨ ìš”ì²­ì€ MCP ë„êµ¬ ìš°ì„ """
        messages = state.get("messages", [])
        if hasattr(messages[-1], 'tool_calls') and messages[-1].tool_calls:
            return "mcp_tools"  # LLMì´ íˆ´ í˜¸ì¶œì„ ê²°ì •í–ˆë‹¤ë©´ ë‹¤ì‹œ mcp_toolsë¡œ
        return "output"

    # LLM ë…¸ë“œì˜ ì¡°ê±´ë¶€ ì—£ì§€ ìˆ˜ì •
    workflow.add_conditional_edges(
        "llm",
        decide_after_llm_simplified,
        {
            "mcp_tools": "mcp_tools",
            "output": "output"
        }
    )

    # íˆ´ ì‹¤í–‰ í›„ LLMìœ¼ë¡œ ëŒì•„ê°€ê¸°
    workflow.add_edge("mcp_tools", "llm")

    # âœ… LLMì˜ ìµœì¢… ì‘ë‹µì€ ì¶œë ¥ìœ¼ë¡œ ì´ë™
    workflow.add_edge("llm", "output")

    # ì¶œë ¥ í›„ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸ (ë£¨í”„ ì œì–´)
    workflow.add_conditional_edges(
        "output",
        factory.should_exit,
        {
            "exit": END,
            "continue": "user_input"
        }
    )

    return workflow.compile()