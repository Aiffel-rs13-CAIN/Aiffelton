# agent-ai/modules/mcp_module.py
import asyncio
import json
import os
import threading
from pathlib import Path
from typing import Dict, Any, List, Optional

from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# MCP ì–´ëŒ‘í„°
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools

# LangGraph / LangChain
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.messages import (
    BaseMessage,
    HumanMessage,
    AIMessage,
    SystemMessage,
    ToolMessage,
)


# -------------------------------
# ë‚´ë¶€ ìœ í‹¸ / í”„ë¡ì‹œ
# íˆ´ ì§‘í•©ì„ ë³´ê´€/êµì²´
# -------------------------------

class _AgentProxy:
    def __init__(self):
        self._agent = None
        self._tools = []
        self._lock = threading.RLock()

    # ì—ì´ì „íŠ¸/íˆ´ ì„¸íŠ¸ êµí™˜
    def swap(self, agent, tools):
        with self._lock:
            self._agent = agent
            self._tools = tools

    # í˜„ì¬ ì—ì´ì „íŠ¸
    def current(self):
        with self._lock:
            return self._agent

    # í˜„ì¬ ë“±ë¡ëœ íˆ´ ëª©ë¡
    def get_tools(self):
        with self._lock:
            return list(self._tools)


def _load_json(path: Path) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def _to_mcp_client_config(cfg: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """
    mcp_config.jsonì˜ "servers"ì™€ "mcpServers" ë¸”ë¡ì„ MultiServerMCPClient í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    ë‘ í˜•ì‹ì„ ëª¨ë‘ ì§€ì›:
    1. "servers": {"name": {"transport": "stdio", "command": "...", ...}} (ê¸°ì¡´ í˜•ì‹)
    2. "mcpServers": {"name": {"command": "...", "args": [...], "cwd": "..."}} (Smithery í˜•ì‹)
    """
    out: Dict[str, Dict[str, Any]] = {}

    # "servers" í˜•ì‹ ì²˜ë¦¬ (ì§ì ‘ ë§Œë“œëŠ” ê²½ìš°)
    for name, s in cfg.get("servers", {}).items():
        t = s.get("transport")
        if t == "stdio":
            out[name] = {
                "transport": "stdio",
                "command": s["command"],
                "args": s.get("args", []),
                "env": s.get("env", {}),
            }
            if "cwd" in s:
                out[name]["cwd"] = s["cwd"]
        elif t == "streamable_http":
            out[name] = {
                "transport": "streamable_http",
                "url": s["url"],
                "headers": s.get("headers", {}),
            }
        else:
            print(f"Unsupported transport in servers: {t}")

    # "mcpServers" í˜•ì‹ ì²˜ë¦¬ (Smithery ìŠ¤íƒ€ì¼)
    for name, s in cfg.get("mcpServers", {}).items():
        server_config = {
            "transport": "stdio",
            "command": s.get("command", "python"),
            "args": s.get("args", []),
            "env": s.get("env", {}),
        }

        if "cwd" in s:
            server_config["cwd"] = s["cwd"]

        out[name] = server_config
        print(f"ğŸ“¦ Added mcpServer: {name} -> {s.get('command')} {s.get('args', [])}")

    return out


def _parse_model_id(raw: str) -> str:
    """
    "openai:gpt-4o-mini" ê°™ì€ í˜•ì‹ë„ í—ˆìš©. ì½œë¡  ë’¤ í† í°ì„ ëª¨ë¸ëª…ìœ¼ë¡œ ì‚¬ìš©.
    """
    if not raw:
        return "gpt-4o"
    return raw.split(":")[-1].strip() or "gpt-4o"


def _normalize_messages(messages: List[Any]) -> List[BaseMessage]:
    """
    ì…ë ¥ messagesë¥¼ LangChain BaseMessageë“¤ë¡œ ì •ê·œí™”.
    """
    norm: List[BaseMessage] = []

    def _from_role(role: str, content: Any) -> BaseMessage:
        r = (role or "").lower()
        if r in ("human", "user"):
            return HumanMessage(content=str(content))
        if r in ("ai", "assistant"):
            return AIMessage(content=str(content))
        if r == "system":
            return SystemMessage(content=str(content))
        if r == "tool":
            return ToolMessage(content=str(content), tool_call_id="dynamic-mcp")
        return HumanMessage(content=str(content))

    for m in messages:
        if isinstance(m, BaseMessage):
            norm.append(m)
        elif isinstance(m, str):
            norm.append(HumanMessage(content=m))
        elif isinstance(m, tuple) and len(m) == 2:
            role, content = m
            norm.append(_from_role(str(role), content))
        elif isinstance(m, dict):
            role = m.get("role", "user")
            content = m.get("content", "")
            norm.append(_from_role(str(role), content))
        else:
            norm.append(HumanMessage(content=str(m)))
    return norm


async def _build_agent(cfg: Dict[str, Any]):
    """
    - MCP ì„œë²„ ì—°ê²° (servers + mcpServers ëª¨ë‘ ì²˜ë¦¬)
    - ì„œë²„ë³„ ì„¸ì…˜ì„ ì—´ì–´ íˆ´ ë¡œë”©/í•„í„°ë§
    - LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    - ReAct agent êµ¬ì„±
    """
    client = MultiServerMCPClient(_to_mcp_client_config(cfg))

    # ëª¨ë“  ì„œë²„ì—ì„œ íˆ´ ìˆ˜ì§‘
    all_tools = []

    # serversì™€ mcpServers ëª¨ë‘ì—ì„œ ì„œë²„ ì´ë¦„ ìˆ˜ì§‘
    all_server_names = list(cfg.get("servers", {}).keys()) + list(cfg.get("mcpServers", {}).keys())

    print(f"ğŸ”Œ Connecting to {len(all_server_names)} MCP servers: {all_server_names}")

    for server_name in all_server_names:
        try:
            async with client.session(server_name) as session:
                ts = await load_mcp_tools(session)
                all_tools.extend(ts)
                print(f"âœ… {server_name}: loaded {len(ts)} tools")
        except Exception as e:
            print(f"âŒ {server_name}: connection failed - {e}")
            # í•œ ì„œë²„ê°€ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

    print("ğŸ§° Total loaded MCP tools:", [t.name for t in all_tools])

    # allow/deny í•„í„°
    allow = set(cfg.get("tool_filters", {}).get("allow", []))
    deny = set(cfg.get("tool_filters", {}).get("deny", []))
    tools = all_tools
    if allow:
        tools = [t for t in tools if t.name in allow]
        print(f"ğŸ” Filtered by allow list: {[t.name for t in tools]}")
    if deny:
        tools = [t for t in tools if t.name not in deny]
        print(f"ğŸ” Filtered by deny list: {[t.name for t in tools]}")

    # LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
    raw_model = cfg.get("model", "gpt-4o")
    model_id = _parse_model_id(raw_model)
    llm = ChatOpenAI(model=model_id, temperature=0)

    # âœ… ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë³€ê²½ (Gemini í˜¸í™˜ì„± ê°œì„ )
    # ì•„ë˜ í”„ë¡¬í”„íŠ¸ëŠ” í…ŒìŠ¤íŠ¸ìš© (ì„ì‹œ)
    base_prompt = cfg.get("prompt", "You are a helpful agent.")
    enhanced_prompt = f"""{base_prompt}

ì‚¬ìš©ìê°€ ì‹œê°„ì´ë‚˜ ë‚ ì§œë¥¼ ë¬¼ì–´ë³´ë©´ get_current_time ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
ìˆ˜í•™ ê³„ì‚°ì´ í•„ìš”í•˜ë©´ calculate_math ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

Available tools: {[t.name for t in tools]}
"""

    # íˆ´ í˜¸ì¶œê³¼ ì¶”ë¡ ì„ ìë™ìœ¼ë¡œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” langgraphì˜ í”„ë¦¬ì…‹ ì—ì´ì „íŠ¸
    agent = create_react_agent(model=llm, tools=tools, prompt=enhanced_prompt)
    return agent, tools


# -------------------------------
# íŒŒì¼ ë³€ê²½ ê°ì§€ í•¸ë“¤ëŸ¬
# -------------------------------

class _ReloadHandler(FileSystemEventHandler):
    def __init__(self, config_path: Path, proxy: _AgentProxy, loop: asyncio.AbstractEventLoop):
        self.config_path = config_path
        self.proxy = proxy
        self.loop = loop
        self._last_mtime = 0

    def on_modified(self, event):
        if event.is_directory:
            return
        if Path(event.src_path) != self.config_path:
            return
        try:
            mtime = os.path.getmtime(self.config_path)
        except FileNotFoundError:
            return
        if mtime == self._last_mtime:
            return
        self._last_mtime = mtime
        asyncio.run_coroutine_threadsafe(self._reload(), self.loop)

    async def _reload(self):
        try:
            cfg = _load_json(self.config_path)
            agent, tools = await _build_agent(cfg)
            self.proxy.swap(agent, tools)
            print("ğŸ” MCP config reloaded and agent swapped (servers + mcpServers)")
        except Exception as e:
            print(f"âŒ Reload failed: {e}")


# -------------------------------
# í¼ë¸”ë¦­ ë§¤ë‹ˆì €
# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—­í• ì„ í•¨
# -------------------------------

class DynamicMCPManager:
    """
    - config/mcp_config.json ë³€ê²½ ì‹œ MCP íˆ´/ì—ì´ì „íŠ¸ ìë™ ì¬êµ¬ì„±
    - "servers"ì™€ "mcpServers" ë‘ í˜•ì‹ ëª¨ë‘ ì§€ì›
    - ì™¸ë¶€ì—ì„œëŠ” ainvoke_messagesì™€ get_available_tools í˜¸ì¶œ ê°€ëŠ¥
    """

    def __init__(self, config_path: str = "config/mcp_config.json"):
        # ê²½ë¡œ ë³´ì •: ìƒëŒ€ê²½ë¡œë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸(agent-ai) ê¸°ì¤€
        base = Path(__file__).resolve().parents[1]  # .../agent-ai
        p = Path(config_path)
        if not p.is_absolute():
            p = (base / p).resolve()
        if not p.exists():
            # ë°±ì—… í›„ë³´
            alt = (base / "config" / "mcp_config.json").resolve()
            if alt.exists():
                p = alt
        self.config_path = p

        self.proxy = _AgentProxy()
        self._observer: Optional[Observer] = None
        self._loop: Optional[asyncio.AbstractEventLoop] = None

    async def start(self):
        """
        íˆ´ ì„¸íŒ… ìµœì´ˆ 1íšŒ ì´ˆê¸°í™” + íŒŒì¼ ê°ì‹œ ì‹œì‘
        """
        self._loop = asyncio.get_running_loop()

        print(f"ğŸ”§ Loading MCP config from: {self.config_path}")
        print(f"ğŸ”§ Config exists: {self.config_path.exists()}")

        if not self.config_path.exists():
            print(f"âŒ MCP config file not found: {self.config_path}")
            # ë¹ˆ ë„êµ¬ë¡œ ì´ˆê¸°í™”
            self.proxy.swap(None, [])
            return

        try:
            cfg = _load_json(self.config_path)
            print(f"ğŸ”§ Config loaded successfully")

            agent, tools = await _build_agent(cfg)
            self.proxy.swap(agent, tools)

            # ì„œë²„ ê°œìˆ˜ í‘œì‹œ
            server_count = len(cfg.get("servers", {})) + len(cfg.get("mcpServers", {}))
            print(
                f"âœ… MCP agent initialized with {server_count} servers, {len(tools)} tools (config={self.config_path})")

            # ë„êµ¬ ëª©ë¡ ì¶œë ¥
            if tools:
                print("ğŸ”§ Available MCP tools:")
                for tool in tools:
                    print(f"   - {tool.name}: {tool.description}")
            else:
                print("âš ï¸  No MCP tools available")

            handler = _ReloadHandler(self.config_path, self.proxy, self._loop)
            self._observer = Observer()
            self._observer.schedule(handler, self.config_path.parent.as_posix(), recursive=False)
            self._observer.start()
            print(f"ğŸ‘€ Watching: {self.config_path}")

        except Exception as e:
            print(f"âŒ Failed to initialize MCP agent: {e}")
            import traceback
            traceback.print_exc()
            # ë¹ˆ ë„êµ¬ë¡œ ì´ˆê¸°í™”
            self.proxy.swap(None, [])

    async def ainvoke_messages(self, state_messages: List[Any]) -> List[BaseMessage]:
        """
        create_react_agent ê·œì•½: {"messages": [...]} I/O
        âœ… Gemini API í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì‹œì§€ ì •ë¦¬ ì¶”ê°€
        """
        agent = self.proxy.current()
        if agent is None:
            raise RuntimeError("MCP agent not ready")

        normalized = _normalize_messages(state_messages)

        # âœ… Gemini APIë¥¼ ìœ„í•œ ë©”ì‹œì§€ ì‹œí€€ìŠ¤ ì •ë¦¬
        cleaned_messages = []
        for msg in normalized:
            # ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ìœ ì§€ (í•¨ìˆ˜ í˜¸ì¶œ ìˆœì„œ ë¬¸ì œ ë°©ì§€)
            if isinstance(msg, HumanMessage):
                cleaned_messages.append(msg)

        if not cleaned_messages:
            # ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return normalized

        try:
            result: Dict[str, Any] = await agent.ainvoke({"messages": cleaned_messages})
            return result.get("messages", result)
        except Exception as e:
            print(f"MCP agent í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ì‹œ ì›ë³¸ ë©”ì‹œì§€ì— ì‹œê°„ ì •ë³´ ì¶”ê°€
            from datetime import datetime
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # ì‹œê°„ ê´€ë ¨ ì‘ë‹µ ìƒì„±
            time_response = AIMessage(content=f"í˜„ì¬ ì‹œê°„ì€ {current_time} ì…ë‹ˆë‹¤.")
            return normalized + [time_response]

    def get_available_tools(self) -> List[Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        return self.proxy.get_tools()

    def stop(self):
        if self._observer:
            self._observer.stop()
            self._observer.join()
            print("ğŸ›‘ File watcher stopped.")