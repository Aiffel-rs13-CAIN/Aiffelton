from typing import Dict, Any
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage

class LLMNode:
    def __init__(self, agent_core):
        self.agent_core = agent_core
    
    def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ë…¸ë“œ ì²˜ë¦¬ ë¡œì§"""
        messages = state.get("messages", [])
        context = state.get("context", "")
        memory_data = state.get("memory", {})
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„±
        system_content = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ ê¸°ì–µí•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ì´ì „ì— ë§í•œ ë‚´ìš©ì´ë‚˜ ìš”ì²­í•œ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê³  í™œìš©í•´ì„œ ë‹µë³€í•˜ì„¸ìš”."""
        
        # ë©”ëª¨ë¦¬ì—ì„œ ê´€ë ¨ ì •ë³´ ì¶”ê°€
        if memory_data.get('status') == 'active' and memory_data.get('related_memories'):
            related_memories = memory_data['related_memories']
            
            if related_memories and isinstance(related_memories, list):
                memory_items = []
                for memory in related_memories[:5]:  # ìµœëŒ€ 5ê°œì˜ ê´€ë ¨ ë©”ëª¨ë¦¬
                    if isinstance(memory, dict):
                        memory_text = memory.get('memory', '')
                    else:
                        memory_text = str(memory)
                    
                    if memory_text.strip():
                        memory_items.append(f"- {memory_text}")
                
                if memory_items:
                    memory_context = "\n".join(memory_items)
                    system_content += f"\n\nğŸ“ ì´ì „ ëŒ€í™”ì—ì„œ ê¸°ì–µí•  ë‚´ìš©:\n{memory_context}\n\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if context:
            system_content += f"\n\n[ì°¸ê³  ì»¨í…ìŠ¤íŠ¸]\n{context}"
        
        # ë©”ì‹œì§€ êµ¬ì„±
        enhanced_messages = [SystemMessage(content=system_content)]
        
        # ê¸°ì¡´ ë©”ì‹œì§€ë“¤ ì¶”ê°€ (ìµœê·¼ ëŒ€í™”ë§Œ)
        if messages:
            # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ í¬í•¨ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            recent_messages = messages[-5:] if len(messages) > 5 else messages
            enhanced_messages.extend(recent_messages)
        
        try:
            # LLM í˜¸ì¶œ
            response = self.agent_core.get_llm().invoke(enhanced_messages)
            
            # ì‘ë‹µì„ ìƒíƒœì— ì¶”ê°€
            updated_messages = list(messages) + [response] if messages else [response]
            
            return {
                "messages": updated_messages,
                "last_response": response.content if hasattr(response, 'content') else str(response),
                "should_exit": state.get("should_exit", False)
            }
            
        except Exception as e:
            print(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            error_message = HumanMessage(content="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {
                "messages": list(messages) + [error_message] if messages else [error_message],
                "last_response": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "should_exit": state.get("should_exit", False)
            }