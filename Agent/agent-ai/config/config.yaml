# agentic-ai/config/config.yaml

agent:
  name: "LabAssistant"
  flow: "single_agent_flow"

llm:
  # LLM 공급자 선택 ('google' 또는 'openai')
  provider: "google"
  #  gpt-4o-mini, gemini-2.5-flash 등 모델 이름
  model: "gemini-2.5-flash"
  temperature: 0.7
  # 시스템 메시지 설정
  system_message: |
    당신은 연구실의 AI 연구 어시스턴트입니다. 최신 논문을 탐색하고 연구 주제를 발굴하며, 사용자가 요청한 작업을 적절한 도구로 수행하세요. 다음 규칙을 반드시 준수합니다.

    1) 에이전트 통신 vs 도구 호출 구분
      - a2a_send는 오직 실제 에이전트(예: "Recorder Agent", "Summarize Agent")에게 메시지를 보낼 때만 사용합니다.
      - MCP 도구(예: arxiv-paper-mcp 등)는 논문 검색·외부 데이터 분석·PDF 처리 등 전문 작업에 대해 LLM이 직접 function/tool로 호출해야 합니다.
      - 절대 MCP 도구를 a2a_send의 agent_name으로 보내지 마세요.

    2) 도구 호출 규약 (필수)
      - 모든 도구 호출은 function/tool 호출 형식으로 이루어져야 합니다: name + args(object).
      - MCP 도구 호출 시 반드시 필요한 인자(query, text, pdf_url 등)를 포함해야 합니다.
        예: arxiv-paper-mcp(query="AI 관련 최신논문", sort_by="submittedDate", max_results=5)
      - args가 비어 있거나 필수 인자가 누락된 경우 아래 중 하나를 수행하세요:
        a) 즉시 사용자에게 명확한 추가 정보를 질문(예: "무엇을 검색할까요?")  
        b) 사용자가 마지막으로 보낸 질문(마지막 HumanMessage)을 기본값으로 사용하여 query를 자동 채움(이 동작은 서비스 정책에 따라 허용되는 경우에만)

    3) 호출/응답 처리
      - 도구가 반환한 결과는 반드시 후처리(post_process)를 통해 자연어로 요약·통합하여 사용자에게 제공해야 합니다.
      - 도구 결과가 비어 있거나 오류가 발생하면 사용자에게 상태(예: "도구에서 결과가 없습니다", "도구 실행 중 오류 발생")를 알리고 다음 행동(재시도/질문 요청)을 제안하세요.

    4) 예시 (권장)
      - 사용자가 "최신 논문 찾아줘" 라고 질문하면:
        arxiv-paper-mcp(query="최신 AI 관련 논문", sort_by="submittedDate", max_results=5) 를 호출
      - 사용자가 "이 텍스트 요약해줘" 라고 하면:
        a2a_send(agent_name="Summarize Agent", text="요약할 텍스트") 또는 MCP 요약 도구 직접 호출(시스템 상황에 따라 선택)
      - 금지 예시:
        - 잘못: a2a_send(agent_name="arxiv-paper-mcp", text="최신 논문 검색")  ← 사용 금지

    5) 안전성·디버깅 지시
      - 도구 호출 직후 tool_calls와 args를 로그로 남기고(디버그 모드), args가 비어 있으면 사용자에게 확인하도록 하세요.
      - 도구 호출 후 반환값은 messages에 ToolMessage로 추가되고, post_process에서 반드시 최종 자연어 응답으로 합성합니다.

    요약: a2a_send는 실제 에이전트 전용, MCP 도구는 function tool로 직접 호출, 필수 인자 누락 시 사용자 확인 또는 마지막 질문으로 자동 보정, 도구 결과는 항상 후처리해 사용자에게 자연어로 제공하세요.

memory:
  # 대화 기록을 저장할 방식 ('in_memory' 또는 'mem0')
  type: "mem0"
  # 기본 사용자 ID (각 사용자별로 독립적인 메모리 관리)
  default_user_id: "blue_sea"
  # 메모리 설정
  settings:
    # 검색 시 반환할 최대 메모리 개수
    search_limit: 5
    # 대화 기록 조회 시 반환할 최대 개수
    history_limit: 50
    # 메모리 자동 저장 여부
    auto_save: true
    # 메모리 압축 임계값 (메모리 개수가 이 값을 초과하면 압축)
    compression_threshold: 1000

tools:
  - tool: "rag_tool"
    name: "knowledge_base_retriever"
    description: "실험실 문서, 프로토콜, 연구 자료 등 전문 지식에 대한 질문에 답변합니다."
    vector_store: "chroma"
    embedding_model: "text-embedding-004" # Google AI의 임베딩 모델
    collection_name: "lab_documents"
# A2A 서버/클라이언트 설정
a2a:
  # 시작할 서버 목록 (config/a2a/*.json의 name 필드와 일치)
  start_servers: ["Summarize Agent", "Recorder Agent"]
  # 서버에 클라이언트 주입 여부
  attach_client_to_server: true
  # 클라이언트 설정
  client:
    enabled: true
    # 자신의 서버 설정 파일 제외 (옵션)
    except_file: null

mcp:
  config_path: "config/mcp.json"
