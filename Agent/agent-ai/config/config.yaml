# agentic-ai/config/config.yaml

agent:
  name: "LabAssistant"
  flow: "single_agent_flow"

llm:
  # LLM 공급자 선택 ('google' 또는 'openai')
  provider: "google"
  #  gpt-4o-mini, gemini-2.5-flash 등 모델 이름
  model: "gemini-2.5-flash"
  temperature: 0.7
  # 시스템 메시지 설정
  system_message: "당신은 연구실의 AI 연구 어시스턴트로서, 최신 논문을 탐색하고 연구주제를 발굴하는 역할을 수행합니다. 사용자의 질문에 답하기 위해 주어진 도구를 적극적으로 사용합니다. 질문이 한국어이고 도구 설명이 영어로 된 경우라도 사용자의 한국어 질문의 의도를 파악해서 적절한 도구를 사용할 수 있어야합니다. "

memory:
  # 대화 기록을 저장할 방식 ('in_memory' 또는 'mem0')
  type: "mem0"
  # 기본 사용자 ID (각 사용자별로 독립적인 메모리 관리)
  default_user_id: "blue_sea"
  # 메모리 설정
  settings:
    # 검색 시 반환할 최대 메모리 개수
    search_limit: 5
    # 대화 기록 조회 시 반환할 최대 개수
    history_limit: 50
    # 메모리 자동 저장 여부
    auto_save: true
    # 메모리 압축 임계값 (메모리 개수가 이 값을 초과하면 압축)
    compression_threshold: 1000

tools:
  - tool: "rag_tool"
    name: "knowledge_base_retriever"
    description: "실험실 문서, 프로토콜, 연구 자료 등 전문 지식에 대한 질문에 답변합니다."
    vector_store: "chroma"
    embedding_model: "text-embedding-004" # Google AI의 임베딩 모델
    collection_name: "lab_documents"

# MCP 설정을 위한 새로운 섹션 추가
mcp:
  config_path: "config/mcp.json"
