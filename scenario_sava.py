import autogen
import testbed_utils

testbed_utils.init()
##############################

# Read the prompt
PROMPT = ""
with open("prompt.txt", "rt") as fh:
    PROMPT = fh.read()

# Read the answer
ANSWER = "__ANSWER__"
try:
    with open("coding/my_test.py", "rt") as fh:
        test_content = fh.read()
        import re
        # assert answer == "C", f"Expected: C, Got: {answer}" í˜•íƒœì—ì„œ ì •ë‹µ ì¶”ì¶œ
        answer_match = re.search(r'assert answer == "([A-E])"', test_content)
        if answer_match:
            ANSWER = answer_match.group(1)
            print(f"ğŸ“‹ ì •ë‹µ ì½ê¸° ì™„ë£Œ: {ANSWER}")
        else:
            print(f"âš ï¸ í…œí”Œë¦¿ ë¯¸ì¹˜í™˜: {ANSWER}")
except Exception as e:
    print(f"âŒ ì •ë‹µ ì½ê¸° ì‹¤íŒ¨: {e}")
    ANSWER = "C"  # ê¸°ë³¸ê°’

# OpenRouter ì „ìš© ì„¤ì • ë¡œë“œ
config_list = autogen.config_list_from_json("OAI_CONFIG_LIST")

# OpenRouter API í˜¸í™˜ì„± í™•ì¸ (api_base ì œê±°)
for config in config_list:
    if "openrouter.ai" not in config.get("base_url", ""):
        raise ValueError(f"âŒ OpenRouter APIë§Œ ì§€ì›í•©ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •: {config.get('base_url')}")


gp_system_message = """
ë‹¹ì‹ ì€ ë¯¸êµ­ ì˜ì‚¬ë©´í—ˆì‹œí—˜(USMLE) Step 1 ë° Step 2 ìˆ˜ì¤€ì˜ ì§€ì‹ì„ ê°–ì¶˜ ìœ ëŠ¥í•œ ì¼ë°˜ì˜ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì—­í• ì€ í™˜ì ì •ë³´, ì„ìƒ ìƒí™©, ì¹˜ë£Œ ì˜µì…˜ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ì§„ë‹¨, ì²˜ì¹˜ ë˜ëŠ” ìœ¤ë¦¬ì  ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì…ë‹ˆë‹¤.

- í•­ìƒ ì˜í•™ì  ì‚¬ì‹¤ê³¼ í‘œì¤€ ì§„ë£Œì§€ì¹¨ì— ê¸°ë°˜í•˜ì—¬ íŒë‹¨í•˜ì„¸ìš”.
- ì„ íƒì§€ ì¤‘ì—ì„œ ê°€ì¥ ì•ˆì „í•˜ê³  í™˜ìì˜ ì´ìµì— ë¶€í•©í•˜ëŠ” ë‹µì„ ê³ ë¥´ì„¸ìš”.
- ë¶ˆí™•ì‹¤í•œ ê²½ìš°ì—ëŠ” ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²ƒì„ íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìœ¼ì„¸ìš”.
- ì§ˆë¬¸ì— ì£¼ì–´ì§„ ì •ë³´ ì™¸ì˜ ì¶”ì¸¡ì€ í”¼í•˜ì„¸ìš”.
- ì„ íƒì§€ëŠ” A, B, C, D, E ë“±ìœ¼ë¡œ ì£¼ì–´ì§€ë©°, ê·¸ ì¤‘ ê°€ì¥ ì ì ˆí•œ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ: "ì •ë‹µì€ Cì…ë‹ˆë‹¤. í•´ë‹¹ ì„ íƒì§€ëŠ” â€¦ ì´ìœ ë¡œ ê°€ì¥ ì ì ˆí•©ë‹ˆë‹¤."
"""

# OpenRouter ì „ìš© LLM ì„¤ì •
llm_config = {
    "config_list": config_list,
    "temperature": 0.1,  # ì˜ë£Œ ì§ˆë¬¸ì´ë¯€ë¡œ ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
    "timeout": 60,
    "cache_seed": None,  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
    "max_tokens": 1000   # OpenRouter ëª¨ë¸ ìµœì í™”
}

print(f"âš™ï¸ OpenRouter LLM ì„¤ì • ì™„ë£Œ - Temperature: {llm_config['temperature']}")
print(f"ğŸ“ ìµœëŒ€ í† í°: {llm_config['max_tokens']}")

assistant = autogen.AssistantAgent(
    "openrouter_medical_ai", 
    system_message=gp_system_message, 
    is_termination_msg=lambda x: x.get("content", "").find("TERMINATE") >= 0,
    llm_config=llm_config)

# ì •ë‹µì„ my_test.pyì—ì„œ ì¶”ì¶œ
correct_answer = "__ANSWER__"

# my_test.pyì—ì„œ ì‹¤ì œ ì •ë‹µ ì½ê¸°
try:
    with open("coding/my_test.py", "r") as f:
        test_content = f.read()
        import re
        # assert answer == "C", f"Expected: C, Got: {answer}" í˜•íƒœì—ì„œ ì •ë‹µ ì¶”ì¶œ
        answer_match = re.search(r'assert answer == "([A-E])"', test_content)
        if answer_match:
            correct_answer = answer_match.group(1)
            print(f"ğŸ“‹ my_test.pyì—ì„œ ì •ë‹µ ì¶”ì¶œ: {correct_answer}")
        else:
            print(f"âš ï¸ í…œí”Œë¦¿ ë¯¸ì¹˜í™˜: {correct_answer}")
except Exception as e:
    print(f"âŒ my_test.py ì½ê¸° ì‹¤íŒ¨: {e}")

print(f"ğŸ¯ ì •ë‹µ: {correct_answer}")
print(f"ğŸ¤– OpenRouter Medical AI ì¤€ë¹„ ì™„ë£Œ")

# ì •ë‹µ í™•ì¸ í•¨ìˆ˜ ê°œì„ 
def check_answer(msg):
    content = msg.get("content", "")
    print(f"[ì±„ì  ì¤‘] assistantì˜ ì‘ë‹µ: {content[:200]}...")
    
    # ë‹µë³€ì—ì„œ ì„ íƒì§€ ì¶”ì¶œ (A, B, C, D, E ì¤‘ í•˜ë‚˜)
    import re
    answer_pattern = r'\b([ABCDE])\b'
    found_answers = re.findall(answer_pattern, content.upper())
    
    if found_answers and correct_answer.upper() in found_answers:
        return f"âœ… ì •ë‹µì…ë‹ˆë‹¤! (ì •ë‹µ: {correct_answer})"
    else:
        return f"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct_answer}ì…ë‹ˆë‹¤."

user_proxy = autogen.UserProxyAgent(
    "user_proxy",
    code_execution_config={"use_docker": False},
    human_input_mode="NEVER",
    default_auto_reply="OpenRouter AIì˜ ë‹µë³€ì„ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.",
    is_termination_msg=lambda x: True  # í•œ ë²ˆë§Œ ì‹¤í–‰
)

print(f"ğŸ¥ OpenRouter ì˜ë£Œ AI í…ŒìŠ¤íŠ¸ ì‹œì‘")
print(f"ğŸ“ ë¬¸ì œ ì¶œì œ ì¤‘...")

# OpenRouter AIì™€ 1:1 ëŒ€í™”
chat_result = user_proxy.initiate_chat(
    assistant, 
    message=PROMPT,
    max_turns=1
)

# ê²°ê³¼ í™•ì¸
if assistant.last_message():
    result = check_answer(assistant.last_message())
    print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼: {result}")

print(f"\nğŸ’¬ OpenRouter AI ì‘ë‹µ:")
if user_proxy.chat_messages.get(assistant):
    for msg in user_proxy.chat_messages[assistant]:
        if msg["role"] == "assistant":
            print(f"ğŸ¤– {config_list[0]['model']}: {msg['content']}")
            break


##############################
testbed_utils.finalize(agents=[user_proxy, assistant])